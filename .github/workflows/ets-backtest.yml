name: ETS • Phase 2 • Backtest

on:
  push:
    branches: [ main, ets_update_2 ]
    paths:
      - "src/**"
      - "scripts/**"
      - "tests/**"
      - "tickers.csv"
      - "requirements.txt"
      - "pyproject.toml"
      - ".github/workflows/ets-backtest.yml"
  pull_request:
    branches: [ main, ets_update_2 ]
  workflow_dispatch:

jobs:
  backtest:
    name: Backtest • signals → history → metrics
    runs-on: ubuntu-latest
    env:
      # Determinism guards
      PYTHONHASHSEED: "0"
      MPLCONFIGDIR: "${{ github.workspace }}/.cache/mpl"
      NUMEXPR_MAX_THREADS: "1"
      OMP_NUM_THREADS: "1"
      OPENBLAS_NUM_THREADS: "1"
      MKL_NUM_THREADS: "1"
      # Ensure imports can find src/ets even before editable install
      PYTHONPATH: "${{ github.workspace }}/src"

      # Fixed date/session for deterministic run (adjust if you prefer)
      ETS_DATE: "2024-10-01"
      ETS_SESSION: "amc"
      ETS_TICKERS: "tickers.csv"  # repo file

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Show Python info
        run: |
          python -V
          which python
          pip -V

      - name: Install deps (runtime + package)
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          pip install -e .
          python - << 'PY'
          import sys, importlib
          print("✔ Importing ets...")
          import ets
          print("✔ ets version OK; modules:", [m for m in sys.modules if m.startswith("ets")][:3], "…")
          PY

      - name: Prepare output dirs
        run: |
          mkdir -p out .ci/lock .cache/mpl
          # Freeze environment for traceability in this job as well
          pip freeze | tee .ci/lock/requirements-lock.txt

      - name: Run deterministic backtest
        shell: bash
        run: |
          set -euo pipefail
          echo ">>> Running backtest for $ETS_DATE [$ETS_SESSION] using $ETS_TICKERS"
          # Prefer the package entrypoint (most stable)
          python -m ets.main \
            --session "$ETS_SESSION" \
            --date "$ETS_DATE" \
            --tickers "$ETS_TICKERS"

          # If your repo also has a script with extra options, keep this as a fallback:
          if [ ! -d out ] || [ -z "$(ls -A out 2>/dev/null || true)" ]; then
            echo "No outputs found after ets.main, attempting scripts/run_backtest.py fallback…"
            if [ -f scripts/run_backtest.py ]; then
              python scripts/run_backtest.py \
                --session "$ETS_SESSION" \
                --date "$ETS_DATE" \
                --tickers "$ETS_TICKERS"
            fi
          fi

      - name: Validate outputs & build manifest
        shell: bash
        run: |
          set -euo pipefail
          python - << 'PY'
          import hashlib, json, os, sys, csv, glob
          OUT_DIR = "out"
          os.makedirs(OUT_DIR, exist_ok=True)
          files = sorted(glob.glob(os.path.join(OUT_DIR, "*")))
          if not files:
            print("✖ No files produced in 'out/' — failing Phase 2.")
            sys.exit(2)

          def sha256(path, chunk=1<<20):
            h = hashlib.sha256()
            with open(path, "rb") as f:
              while True:
                b = f.read(chunk)
                if not b: break
                h.update(b)
            return h.hexdigest()

          summary = {"files": [], "errors": [], "warnings": []}
          for p in files:
            rec = {"path": p, "hash": sha256(p), "size_bytes": os.path.getsize(p)}
            if p.endswith(".csv"):
              try:
                with open(p, newline="") as f:
                  r = csv.reader(f)
                  rows = list(r)
                rec["rows"] = max(0, len(rows)-1) if rows else 0
                rec["headers"] = rows[0] if rows else []
                if rec["rows"] <= 0:
                  summary["warnings"].append(f"CSV empty: {p}")
              except Exception as e:
                summary["errors"].append(f"CSV read failed for {p}: {e}")
            summary["files"].append(rec)

          # At least one CSV with >=1 data row required for success
          has_data_csv = any(
            f["path"].endswith(".csv") and f.get("rows", 0) > 0
            for f in summary["files"]
          )
          manifest_path = os.path.join(OUT_DIR, "manifest.json")
          with open(manifest_path, "w") as f:
            json.dump(summary, f, indent=2)
          print(json.dumps(summary, indent=2))

          if summary["errors"]:
            print("✖ Errors during output validation.")
            sys.exit(3)
          if not has_data_csv:
            print("✖ No non-empty CSVs detected — failing Phase 2.")
            sys.exit(4)
          PY

      - name: Upload artifacts (out/)
        uses: actions/upload-artifact@v4
        with:
          name: ets-backtest-out
          path: |
            out/**
            .ci/lock/requirements-lock.txt
          if-no-files-found: error

      - name: Summarize run
        run: |
          echo "### Backtest complete for ${ETS_DATE} (${ETS_SESSION})" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- Python: \`$(python -V)\`" >> $GITHUB_STEP_SUMMARY
          echo "- Locked deps saved to \`.ci/lock/requirements-lock.txt\`" >> $GITHUB_STEP_SUMMARY
          echo "- Artifacts: \`ets-backtest-out\` (includes \`out/\` and manifest)" >> $GITHUB_STEP_SUMMARY
